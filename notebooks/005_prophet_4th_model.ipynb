{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu.omura/workspace/github/pjme/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_yearly, plot_seasonality\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.processing import preprocessing\n",
    "\n",
    "# https://stackoverflow.com/questions/66667909/stop-printing-infocmdstanpystart-chain-1-infocmdstanpyfinish-chain-1\n",
    "logger = logging.getLogger(\"cmdstanpy\")\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"The behavior of DatetimeProperties.to_pydatetime is deprecated\")\n",
    "\n",
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(DATA_DIR / \"PJME_hourly.csv\")\n",
    "split_date = datetime.datetime(2015, 1, 1)\n",
    "\n",
    "df = preprocessing(df)\n",
    "df_train, df_test = df.filter(pl.col(\"ds\") <= split_date), df.filter(pl.col(\"ds\") > split_date)\n",
    "df, df_train, df_test = df.to_pandas(), df_train.to_pandas(), df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4thモデル\n",
    "- 夏場と冬場の傾向を捉える\n",
    "    - `add_seasonality`でカスタムの季節変動を加える\n",
    "      - `condition_name`で適用するデータポイントを絞ることができる\n",
    "    - 祝日効果として夏場や冬場のピークを組み込む\n",
    "    - `add_regressor`で気温などの外部要因をモデルに組み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add_seasonalityの追加\n",
    "`add_seasonality`は精度向上しない。夏以外の期間にも、period=92の周期変動を適用するので、ちょっとモデリングに無理があるかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:51<00:00, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_seasonality=1 MAE: 5110.973782590863\n",
      "weekly_seasonality=3 MAE: 5105.000975367784\n",
      "weekly_seasonality=5 MAE: 5105.163656682453\n",
      "weekly_seasonality=7 MAE: 5105.011670019132\n",
      "weekly_seasonality=9 MAE: 5107.398180108165\n",
      "best_fourier_order: 3, best_score: 5105.000975367784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "best_fourier_order, best_score = None, np.inf\n",
    "for i in tqdm(range(1, 11, 2), total=len(range(1, 11, 2))):\n",
    "    model = Prophet(yearly_seasonality=2, weekly_seasonality=1)\n",
    "    # 6/15-9/15までの92日間をhigh_seasonとして定義\n",
    "    model.add_seasonality(name=\"summer\", period=92, fourier_order=i)\n",
    "    model.fit(df_train)\n",
    "\n",
    "    preds = model.predict(df_test)\n",
    "    mae = mean_absolute_error(\n",
    "        df_test[\"y\"],\n",
    "        pl.DataFrame(preds).filter(pl.col(\"ds\") > split_date)[\"yhat\"],\n",
    "    )\n",
    "    if mae < best_score:\n",
    "        best_score = mae\n",
    "        best_fourier_order = i\n",
    "    \n",
    "    outputs.append(f\"weekly_seasonality={i} MAE: {mae}\")  # best so far: 5100.535160661208\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)\n",
    "print(f\"best_fourier_order: {best_fourier_order}, best_score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "毎年`6/15-9/15`を夏と定義し`is_summer`フラグをデータに追加。  \n",
    "`is_summer`フラグが`True`の期間に対してのみ、`add_seasonality`を追加してみる。\n",
    "- 結果\n",
    "  - 効果なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_summer_df = pl.DataFrame(df)\n",
    "add_summer_df = add_summer_df.with_columns(\n",
    "    (\n",
    "        pl.col(\"ds\").dt.month().is_in([7, 8, 9]) |\n",
    "        ((pl.col(\"ds\").dt.month() == 6) & (pl.col(\"ds\").dt.day() >= 15)) |\n",
    "        ((pl.col(\"ds\").dt.month() == 9) & (pl.col(\"ds\").dt.day() <= 15))\n",
    "    ).cast(pl.UInt8).alias(\"is_summer\")\n",
    ")\n",
    "\n",
    "add_summer_df_train, add_summer_df_test = add_summer_df.filter(pl.col(\"ds\") <= split_date), add_summer_df.filter(pl.col(\"ds\") > split_date)\n",
    "add_summer_df, add_summer_df_train, add_summer_df_test = add_summer_df.to_pandas(), add_summer_df_train.to_pandas(), add_summer_df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5113.1217911818\n"
     ]
    }
   ],
   "source": [
    "model = Prophet(yearly_seasonality=2, weekly_seasonality=1)\n",
    "model.add_seasonality(name=\"summer\", period=92, fourier_order=3, condition_name=\"is_summer\")\n",
    "model.fit(add_summer_df_train)\n",
    "\n",
    "preds = model.predict(add_summer_df_test)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "    add_summer_df_test[\"y\"],\n",
    "    pl.DataFrame(preds).filter(pl.col('ds') > split_date)[\"yhat\"],\n",
    ")\n",
    "print(f\"MAE: {mae}\")  # not set condition_name MAE: 5105.000975367784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add_regressorの追加\n",
    "`add_regressor`で、シカゴの過去の気温情報を加えてみる。  \n",
    "データは、[NOAA](https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/locations/CITY:US170006/detail)から取得。  \n",
    "今回の電力消費データは、PJMというアメリカ東部の電力会社が集計したものであり、下記の州を管轄している。下記の週の中でもっと人口が多い都市であるオハイオ州のシカゴの気温データを使う。\n",
    "```\n",
    "It is part of the Eastern Interconnection grid operating an electric transmission system serving all or parts of Delaware, Illinois, Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania, Tennessee, Virginia, West Virginia, and the District of Columbia\n",
    "```\n",
    "https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "収集データ場所: CHICAGO OHARE INTERNATIONAL AIRPORT, IL US\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>high</th><th>low</th><th>ds</th></tr><tr><td>f32</td><td>f32</td><td>datetime[ns]</td></tr></thead><tbody><tr><td>2.5</td><td>1.0</td><td>2002-01-01 00:00:00</td></tr><tr><td>3.1</td><td>1.1</td><td>2002-01-02 00:00:00</td></tr><tr><td>2.8</td><td>1.2</td><td>2002-01-03 00:00:00</td></tr><tr><td>3.8</td><td>1.8</td><td>2002-01-04 00:00:00</td></tr><tr><td>3.5</td><td>2.8</td><td>2002-01-05 00:00:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────┬─────┬─────────────────────┐\n",
       "│ high ┆ low ┆ ds                  │\n",
       "│ ---  ┆ --- ┆ ---                 │\n",
       "│ f32  ┆ f32 ┆ datetime[ns]        │\n",
       "╞══════╪═════╪═════════════════════╡\n",
       "│ 2.5  ┆ 1.0 ┆ 2002-01-01 00:00:00 │\n",
       "│ 3.1  ┆ 1.1 ┆ 2002-01-02 00:00:00 │\n",
       "│ 2.8  ┆ 1.2 ┆ 2002-01-03 00:00:00 │\n",
       "│ 3.8  ┆ 1.8 ┆ 2002-01-04 00:00:00 │\n",
       "│ 3.5  ┆ 2.8 ┆ 2002-01-05 00:00:00 │\n",
       "└──────┴─────┴─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chicago_df = pl.read_csv(DATA_DIR / \"temperature\" / \"chicago.csv\", dtypes={\"high\": pl.Float32, \"low\": pl.Float32})\n",
    "print(f\"収集データ場所: {chicago_df['NAME'][0]}\")\n",
    "\n",
    "chicago_df = chicago_df.with_columns(\n",
    "    pl.col(\"DATE\").str.to_datetime(time_unit=\"ns\").alias(\"ds\")\n",
    ").drop(\"NAME\", \"DATE\")\n",
    "display(chicago_df.head())\n",
    "\n",
    "# 元データと結合\n",
    "df = pl.DataFrame(df).join(chicago_df, on=\"ds\", how=\"left\")\n",
    "df = df.with_columns(\n",
    "    pl.col(\"high\").forward_fill(),\n",
    "    pl.col(\"low\").forward_fill(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残念ながらスコアは向上せず。日単位で同じ気温を使っていることが問題かも。  \n",
    "prophetモデルは結構繊細な印象。LightGBMはこの特徴量でスコアを向上させている。  \n",
    "しっかりEDAを行って適切に要素をモデルに組み込んでいく必要がありそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5124.377598955317\n"
     ]
    }
   ],
   "source": [
    "model = Prophet(yearly_seasonality=2, weekly_seasonality=1)\n",
    "model.add_regressor(\"high\")\n",
    "model.add_regressor(\"low\")\n",
    "\n",
    "df = df.drop_nulls()\n",
    "\n",
    "df_train, df_test = df.filter(pl.col(\"ds\") <= split_date), df.filter(pl.col(\"ds\") > split_date)\n",
    "df, df_train, df_test = df, df_train.to_pandas(), df_test.to_pandas()\n",
    "model.fit(df_train)\n",
    "preds = model.predict(df_test)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "    df_test[\"y\"],\n",
    "    pl.DataFrame(preds).filter(pl.col(\"ds\") > split_date)[\"yhat\"],\n",
    ")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その他、変化点の検知を調整したり、加法モデルから乗法モデルに変更したり改善の余地がある。  \n",
    "ただ精度という観点ではLightGBMには遠く及ばない。しかしより直感的にモデルに情報を組み込むことができ、解釈性に富んでいるのが大きなメリット"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
